{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOKiKUMn7kPFRZndYqOqFI0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AatiqahHarmine/PRODIGY_GA_02/blob/main/Task_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TASK - 02"
      ],
      "metadata": {
        "id": "YGBNB0lk6k0E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilize pre-trained generative models like DALL-E-mini or Stable Diffusion to create images from text prompts."
      ],
      "metadata": {
        "id": "hq0MLxcK6oYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 1 : Installing all required libraries:\n",
        "\n",
        "diffusers, transformers, scipy, accelerate\n",
        "\n",
        ". diffusers\n",
        "\n",
        "Main purpose: Generate images from text prompts.\n",
        "\n",
        "Why: It's the core library from Hugging Face for running models like Stable Diffusion.\n",
        "\n",
        "It handles pipelines, image generation steps, schedulers, and model loading.\n",
        "\n",
        ". transformers\n",
        "\n",
        "Main purpose: Tokenize text and handle transformer-based models.\n",
        "\n",
        "Why: Models like Stable Diffusion often use a CLIP tokenizer or text encoder from transformers to understand the prompt.\n",
        "\n",
        ".  scipy\n",
        "\n",
        "Main purpose: Scientific computing and math utilities.\n",
        "\n",
        "Why: Some schedulers and post-processing steps in diffusion models (like image denoising) depend on SciPy functions.\n",
        "\n",
        ". accelerate\n",
        "\n",
        "Main purpose: Simplifies running models on GPU, CPU, or multiple devices.\n",
        "\n",
        "Why: Helps the diffusers library run efficiently, especially when you're using a CUDA-enabled GPU."
      ],
      "metadata": {
        "id": "aRnLXdWJ92I9"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6172291"
      },
      "source": [
        "!pip install diffusers transformers scipy accelerate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step - 2 : Loaded a pre-trained model (runwayml/stable-diffusion-v1-5) and sent it to GPU\n",
        "\n",
        "1. Imports required libraries <br>\n",
        "from diffusers import StableDiffusionPipeline\n",
        "import torch\n",
        "\n",
        "2. Loads the Stable Diffusion v1.5 model in half-precision (float16) for faster performance: <br>\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    \"runwayml/stable-diffusion-v1-5\",\n",
        "    torch_dtype=torch.float16\n",
        ")\n",
        "\n",
        "3. Moves the model to GPU for accelerated inference: <br>\n",
        "pipe = pipe.to(\"cuda\")\n",
        "\n",
        "4. Defines a text prompt and generates an image from it: <br>\n",
        "prompt = \"A steampunk flying ship floating over the ocean at sunset\"\n",
        "image = pipe(prompt).images[0]\n",
        "\n",
        "5. Saves the generated image locally: <br>\n",
        "image.save(\"generated_image_diffusers.png\")\n",
        "print(\"Image generated and saved as generated_image_diffusers.png\")"
      ],
      "metadata": {
        "id": "ogLusIlN-6hy"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6449966f"
      },
      "source": [
        "from diffusers import StableDiffusionPipeline\n",
        "import torch\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16)\n",
        "pipe = pipe.to(\"cuda\")\n",
        "\n",
        "prompt = \"A steampunk flying ship floating over the ocean at sunset\"\n",
        "\n",
        "image = pipe(prompt).images[0]\n",
        "\n",
        "image.save(\"generated_image_diffusers.png\")\n",
        "\n",
        "print(\"Image generated and saved as generated_image_diffusers.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ". Below line will display the generated image right in your notebook or Colab output"
      ],
      "metadata": {
        "id": "r_FhIwh0BPTu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "display(Image(filename=\"generated_image_diffusers.png\"))"
      ],
      "metadata": {
        "id": "WbxrdsjzyHuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step - 3 : Generated multiple images from a list of text prompts"
      ],
      "metadata": {
        "id": "9HgNG8bHAOIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import StableDiffusionPipeline\n",
        "import torch\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    \"runwayml/stable-diffusion-v1-5\",\n",
        "    torch_dtype=torch.float16\n",
        ").to(\"cuda\")\n",
        "\n",
        "prompts = [\n",
        "    \"A steampunk flying ship floating over the ocean at sunset\",\n",
        "    \"A futuristic city skyline at night with flying cars\",\n",
        "    \"A cozy cabin in a snowy forest under northern lights\"\n",
        "]\n",
        "\n",
        "for i, prompt in enumerate(prompts, start=1):\n",
        "    image = pipe(prompt).images[0]\n",
        "    filename = f\"generated_image_{i}.png\"\n",
        "    image.save(filename)\n",
        "    print(f\"Image saved as {filename}\")"
      ],
      "metadata": {
        "id": "-49TsqLpyl7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step - 4 : Saved all generated images with appropriate filenames\n",
        "\n",
        "prompts = [\n",
        "    \"A steampunk flying ship floating over the ocean at sunset\",\n",
        "    \"A futuristic city skyline at night with flying cars\",\n",
        "    \"A cozy cabin in a snowy forest under northern lights\"\n",
        "]\n",
        "\n",
        "for i, prompt in enumerate(prompts, start=1):\n",
        "    image = pipe(prompt).images[0]\n",
        "    filename = f\"generated_image_{i}.png\"\n",
        "    image.save(filename)\n",
        "    print(f\"Image saved as {filename}\")\n",
        "\n",
        ". Loops over multiple prompts.\n",
        "\n",
        ". Saves each image with a unique, clear filename.\n",
        "\n",
        ". Uses enumerate(..., start=1) to number images starting from 1.\n",
        "\n",
        ". Prints confirmation for each saved image."
      ],
      "metadata": {
        "id": "c9hJo7O7AWhM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step - 5 : Displayed the images inline in the notebook using IPython.display"
      ],
      "metadata": {
        "id": "syPfJbohAZW5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "for i in range(1, 4):\n",
        "    print(f\"Displaying generated_image_{i}.png\")\n",
        "    display(Image(filename=f\"generated_image_{i}.png\"))\n"
      ],
      "metadata": {
        "id": "JkZGczxJ0T6U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}